{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data= pd.read_excel('output.xlsx')\n",
    "all_data['Date + Time'] = pd.to_datetime(all_data['Date + Time'])\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date + Time']).dt.date\n",
    "\n",
    "all_data['Same Bound'] = all_data['Bound'] == all_data['Bound'].shift(1)\n",
    "all_data['Same Lane'] = all_data['Lane'] == all_data['Lane'].shift(1)    \n",
    "\n",
    "all_data.loc[(all_data['Same Bound'] == True) & (all_data['Same Lane'] == True), 'Gap Time'] = all_data['Date + Time'].diff().dt.seconds\n",
    "all_data.loc[all_data['Same Bound'] == False, 'Gap Time'] = pd.NA\n",
    "all_data.loc[all_data['Same Lane'] == False, 'Gap Time'] = pd.NA\n",
    "\n",
    "cols = ['Gap Time']\n",
    "all_data.loc[:,cols] = all_data.loc[:,cols].bfill()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming of Unamed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11,27):\n",
    "    num = (i - 7) // 2\n",
    "    if i % 2 == 0:\n",
    "        new_column_name = 'Axle Spacing ' + str(num)\n",
    "    else:\n",
    "        new_column_name = 'Axle Weight ' + str(num)\n",
    "    column_name = 'Unnamed: ' + str(i)\n",
    "    print(f'{column_name=}, {new_column_name=}')\n",
    "    all_data.rename(columns={column_name: new_column_name}, inplace=True)\n",
    "all_data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported From 'Data_handle.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time as t\n",
    "\n",
    "def vehicular_flow_in_hours_setup():\n",
    "        \n",
    "    def generate_time(time_list):\n",
    "        for h in range(24):\n",
    "            time_list.append(t(h).strftime(\"%H\"))\n",
    "        return\n",
    "\n",
    "    # Create the Time column, where it is in the string format of hour:minute in 1 minute increments\n",
    "    all_data['Time'] = all_data['Date + Time'].dt.floor('h')\n",
    "    all_data['Time'] = all_data['Time'].dt.strftime(\"%H\")\n",
    "\n",
    "    # Make a time list to store all the x data from 00:00 to 23:59\n",
    "    time_list = []\n",
    "    generate_time(time_list)\n",
    "    dict = {\"Time\": time_list}\n",
    "\n",
    "    # Loops over the number of recorded date\n",
    "    date_list = all_data['Date'].unique()\n",
    "    for date in date_list:\n",
    "        vehicle_flow = []\n",
    "        # Loops over each minute\n",
    "        for time in time_list:\n",
    "            # Tallies the number of vehicle that is recorded in that minute. -> convert the unit from veh/min to veh/hr\n",
    "            # ? Times 60 for the total numebr of cars to convert: cars per min to cars per hour\n",
    "            tmp = all_data[(all_data['Date']==date) & (all_data['Time']==time)]\n",
    "            hourly_flow = len(tmp.index)\n",
    "            if hourly_flow < 100: \n",
    "                hourly_flow = 0\n",
    "            vehicle_flow.append(hourly_flow)\n",
    "        dict[date] = vehicle_flow\n",
    "    # print()\n",
    "    VF_testing = pd.DataFrame(dict)\n",
    "\n",
    "    # Finding the Average Values\n",
    "    VF_testing['Total'] = VF_testing.iloc[:,1:6].sum(axis=1)\n",
    "    VF_testing['Unique Dates'] = VF_testing.iloc[:,1:6].astype(bool).sum(axis=1)\n",
    "\n",
    "    VF_testing['Average'] = VF_testing['Total'] / VF_testing['Unique Dates']\n",
    "    VF_testing['Average'] =  VF_testing['Average'].fillna(0)\n",
    "    \n",
    "    return VF_testing, time_list, date_list\n",
    "\n",
    "def average_vehicular_flow():\n",
    "    VF_testing, time_list, date_list = vehicular_flow_in_hours_setup()\n",
    "    np_vehicular_flow = VF_testing['Average'].to_numpy() \n",
    "    np_time_list = time_list\n",
    "    print(f'{np_vehicular_flow=}')\n",
    "    print(f'{np_time_list=}')\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def vehicular_flow_in_hours_with_average_and_scatter():\n",
    "\n",
    "    VF_testing, time_list, date_list = vehicular_flow_in_hours_setup()\n",
    "\n",
    "    # graph plot the average value\n",
    "    plt.plot(time_list, VF_testing['Average'],'.-', label='Average')\n",
    "    print(VF_testing['Average'])\n",
    "\n",
    "    # Scatter Plot\n",
    "    for date in date_list:\n",
    "        # removes the time data for when there is no vehicle recorded\n",
    "        tmp = np.array(VF_testing[date].astype(float))\n",
    "        tmp[tmp==0] = np.nan\n",
    "        \n",
    "        plt.scatter(VF_testing['Time'], tmp, label=date)\n",
    "\n",
    "    plt.xticks(time_list, rotation=70)\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time of Day (24 hour format)')\n",
    "    plt.ylabel('Vehicular Flow (veh/h)')\n",
    "    plt.title('Hourly Vehicular Flow per Lane Across Different Times of Day')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return \n",
    "vehicular_flow_in_hours_with_average_and_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For generate_daily_vehicle_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Function Template for finding distribution from dataset, plotting the dataset, and interpolating data\n",
    "from importlib import reload\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "database = {}\n",
    "\n",
    "def filter_all_data(vehicle_class_column_name, vehicle_class_value, df=all_data):\n",
    "    return df[df[vehicle_class_column_name] == vehicle_class_value]\n",
    "\n",
    "# optimised by ChatGPT\n",
    "def obtain_distribution(total_weight_column_name: str, df: pd.DataFrame = all_data):\n",
    "    counts = df.groupby(total_weight_column_name).size().reset_index(name='Count')\n",
    "    total_rows = counts['Count'].sum()\n",
    "    counts['Percentage'] = counts['Count'] / total_rows\n",
    "    # counts['Cumulative Probability'] = (counts['Count'] / total_rows).cumsum()\n",
    "\n",
    "    counts['Cumulative Probability'] = counts['Percentage'].cumsum()\n",
    "    # * Numpy\n",
    "    # np_cumu_distribution = counts[[total_weight_column_name, 'Cumulative Probability']].to_numpy().T\n",
    "    # return np_cumu_distribution\n",
    "\n",
    "    # * Pandas\n",
    "    # output = counts.loc[:,[total_weight_column_name,'Cumulative Probability' ]]    \n",
    "    output = counts.loc[:,[total_weight_column_name,'Percentage' ]]    \n",
    "    return output\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_unit(axis: str):\n",
    "    if axis == 'Gap Time': \n",
    "        axis += ' (s)'\n",
    "    elif axis == 'Total Weight': \n",
    "        axis += ' (kg)'\n",
    "    elif axis == 'Speed': \n",
    "        axis += ' (km/h)'\n",
    "    elif 'Axle Weight' in axis: \n",
    "        axis += ' (kg)'\n",
    "    elif 'Axle Spacing' in axis: \n",
    "        axis += ' (mm)'\n",
    "    return axis\n",
    "\n",
    "def plot_distribution(df:pd.DataFrame, additional_string:str = ''):\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    ax.set_title(f'For Cars of {additional_string}:',fontweight='bold')\n",
    "    x_axis = df.columns[0]\n",
    "    y_axis = df.columns[-1]\n",
    "\n",
    "    tmp_x_axis = df.columns[0]\n",
    "\n",
    "    tmp_y_axis = df.columns[-1]\n",
    "\n",
    "    if (x_axis == 'Bound')| (x_axis == 'Date + Time')| (x_axis == 'Seq No')| (x_axis == 'Lane')| (x_axis == 'Class')| (x_axis == 'No of Axle'): \n",
    "        ax.bar(df[x_axis], df[y_axis])\n",
    "    else:\n",
    "        # ax.scatter(df[x_axis], df[y_axis], s=20)\n",
    "        ax.plot(df[x_axis], df[y_axis],color='C0', marker='o', linestyle='-' )\n",
    "\n",
    "    ax=reload(plt)\n",
    "    if y_axis == 'Cumulative Probability':\n",
    "        fig.suptitle(f'CDF of {x_axis}')\n",
    "    else:\n",
    "        fig.suptitle(f'{x_axis} against {y_axis}')\n",
    "\n",
    "    # print(f'{df.iloc[-1,0]}=')\n",
    "    ax.xlim(0,df.iloc[-1,0])\n",
    "    # Show the major grid and style it slightly.\n",
    "    plt.grid(True, which='both')\n",
    "    plt.grid(which='major', color='black', linewidth=0.8)\n",
    "    # Show the minor grid as well. Style it in very light gray as a thin,\n",
    "    # dotted line.\n",
    "    plt.grid(which='minor', color='black', linestyle=':', linewidth=1)\n",
    "    # Make the minor ticks and gridlines show.\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    plt.legend(loc=0)\n",
    "    \n",
    "    x_axis = add_unit(x_axis)\n",
    "    y_axis = add_unit(y_axis)\n",
    "\n",
    "    ax.xlabel(x_axis)\n",
    "    ax.ylabel(y_axis)\n",
    "\n",
    "    # from pathlib import Path\n",
    "\n",
    "    filename = f'Graphs/CPD_{additional_string}_{tmp_y_axis}_{tmp_x_axis}.png'\n",
    "    # my_file = Path(filename)\n",
    "    # if not my_file.is_file():\n",
    "    # file exists\n",
    "    plt.savefig(filename)\n",
    "   \n",
    "    return\n",
    "\n",
    "# Optimised by ChatGPT\n",
    "def generate_and_interpolate_value(numpy_array: np.float64, total_weight_key: str):\n",
    "\n",
    "    numpy_array = numpy_array.to_numpy().T\n",
    "\n",
    "\n",
    "    random_prob = random.random()\n",
    "    if total_weight_key in ['Bound', 'Date + Time', 'Seq No', 'Lane', 'Class', 'No of Axle']:\n",
    "        sorter = np.argsort(numpy_array[1])\n",
    "        tmp = np.searchsorted(numpy_array[1],[random_prob,],side='left', sorter=sorter)[0]\n",
    "\n",
    "        interpolated_value = int(numpy_array[0][tmp])\n",
    "\n",
    "    else:\n",
    "        interpolated_value = np.interp(random_prob, numpy_array[1], numpy_array[0])\n",
    "\n",
    "\n",
    "    return interpolated_value\n",
    "\n",
    "\n",
    "def double_filter_and_generate_variable(vehicle_class_key1: str, vehicle_class_value1: int, vehicle_class_key2: str, vehicle_class_value2: int , total_weight_key: str, )-> float :\n",
    "    \n",
    "    # * Timesaving techniques!\n",
    "    # Find the set of queries from the database to see if it is run before or not\n",
    "    filter_key = f'{str(vehicle_class_key1)} = {str(vehicle_class_value1)} and {str(vehicle_class_key2)} = {str(vehicle_class_value2)}'\n",
    "    database_key = f'{filter_key} {str(total_weight_key)}'\n",
    "    # print(f'DATABASE KEY IS {database_key}')\n",
    "\n",
    "    #* If it has been run before \n",
    "\n",
    "    if database_key in database:\n",
    "        # * call the distribution from database\n",
    "        distribution = database[database_key]\n",
    "        # print(f'RECALLED DISTRIBUTION FROM DATABASE WITH KEY {database_key}')\n",
    "\n",
    "    # * If it has never been run before\n",
    "    else:\n",
    "        # * generate the distribution from scratch\n",
    "        # * filtering the data twice \n",
    "        tmp_df = filter_all_data(vehicle_class_key1, vehicle_class_value1)\n",
    "        tmp_df = filter_all_data(vehicle_class_key2, vehicle_class_value2,df=tmp_df)\n",
    "\n",
    "        # * Now we count the data that is within the filtered dataframe to create CDF\n",
    "        distribution = obtain_distribution(total_weight_key, tmp_df)\n",
    "        \n",
    "        # * Update the database so it has the new query \n",
    "        # print(f'ASSIGNED DISTRIBUTION TO DATABASE WITH KEY {database_key}')\n",
    "        database[database_key] = distribution\n",
    "    \n",
    "    # * Return Error when distribution found is empty. \n",
    "    # if distribution.empty:\n",
    "    #     print(f'Dtaframe with key = {total_weight_key} is empty.')\n",
    "    #     return\n",
    "\n",
    "    #* Plots the distribution\n",
    "    # plot_distribution(distribution, filter_key)\n",
    "\n",
    "    #* Generates a random num (0,1), then finds its corresponding value\n",
    "    output = generate_and_interpolate_value(distribution, total_weight_key)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def generate_variable(vehicle_class_key: str, vehicle_class_value: int , total_weight_key: str)-> float :\n",
    "    \n",
    "    # * Timesaving techniques!\n",
    "    # Find the set of queries from the database to see if it is run before or not\n",
    "    filter_key = f'{str(vehicle_class_key)} = {str(vehicle_class_value)}'\n",
    "    database_key = f'{filter_key} {str(total_weight_key)}'\n",
    "\n",
    "\n",
    "    #* If it has been run before \n",
    "    if database_key in database:\n",
    "        # * call the distribution from database\n",
    "        distribution = database[database_key]\n",
    "        # print(f'RECALLED DISTRIBUTION FROM DATABASE WITH KEY {database_key}')\n",
    "    \n",
    "    # * If it has never been run before\n",
    "    else:\n",
    "        # * generate the distribution from scratch\n",
    "        # * filtering the data once\n",
    "\n",
    "        # start = time.time()\n",
    "        tmp_df = filter_all_data(vehicle_class_key, vehicle_class_value)\n",
    "        # end = time.time()\n",
    "        # print(f'time for filter_all_data is {end-start}')\n",
    "        \n",
    "        # * Now we count the data that is within the filtered dataframe to create CDF\n",
    "        # start = time.time()\n",
    "        distribution = obtain_distribution(total_weight_key, tmp_df)\n",
    "        # end = time.time()\n",
    "        # print(f'time for obtain_distribution is {end-start}')\n",
    "        \n",
    "        # * Update the database so it has the new query \n",
    "        database[database_key] = distribution\n",
    "    \n",
    "    # * Return Error when distribution found is empty. \n",
    "    # if len(distribution) == 0:\n",
    "    #     print(f'Dtaframe with key = {total_weight_key} is empty.')\n",
    "    #     return\n",
    "    \n",
    "    #* Plots the distribution\n",
    "    plot_distribution(distribution, filter_key)\n",
    "\n",
    "    #* Generates a random num (0,1), then finds its corresponding value\n",
    "    # start = time.time()\n",
    "    output = generate_and_interpolate_value(distribution, total_weight_key)\n",
    "    # end = time.time()\n",
    "    # print(f'time for generate_and_interpolate_value is {end-start}')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def normalise_axle_weights(axle_weight_list: list):\n",
    "    sum = 0\n",
    "    for axle_weight in axle_weight_list:\n",
    "        sum += axle_weight\n",
    "    output = np.array([])\n",
    "    for axle_weight in axle_weight_list:\n",
    "        output = np.append(output, axle_weight / sum)\n",
    "    return output\n",
    "\n",
    "def distribute_total_weight(axle_weight_list: list, GVW: float):\n",
    "    output = np.array([])\n",
    "    for axle_weight_proportion in axle_weight_list:\n",
    "        output = np.append(output, axle_weight_proportion * GVW)\n",
    "    return output\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minor Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For generate_daily_vehicle_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_vehicle_class():\n",
    "    \n",
    "    # Hard Code\n",
    "    cumu_proportion = np.array([0.3712258 , 0.70580101, 1.        ])\n",
    "    cumu_distribution = np.array([0.00000000e+00, 6.65190000e-04, 5.33101100e-02, 1.25910680e-01,\n",
    "       2.88438400e-01, 3.74976250e-01, 5.11910050e-01, 8.76781760e-01,\n",
    "       1.00000001e+00])\n",
    "\n",
    "    \n",
    "    roll = random.uniform(0, 1)\n",
    "    if roll < cumu_proportion[0]: # HDV\n",
    "        # * determine detailed class 3-9\n",
    "        # distribution:list[float] = finding_HDV_class_distribution()\n",
    "        # cumu_distribution = np.array([0.00000000e+00, 6.65190000e-04, 5.33101100e-02, 1.25910680e-01,2.88438400e-01, 3.74976250e-01, 5.11910050e-01, 8.76781760e-01,1.00000001e+00])\n",
    "        output = np.searchsorted(cumu_distribution,[random.uniform(0, 1),],side='left')[0]\n",
    "        return 1, output\n",
    "    elif roll < cumu_proportion[1]: # Private Car\n",
    "        return 2, 2\n",
    "    else: # Motorbike\n",
    "        return 3, 1\n",
    "\n",
    "def generate_GVW(vehicle_class: int, EV_proportion: float) -> float:\n",
    "    output = generate_variable('Class', vehicle_class, 'Total Weight')\n",
    "    return (output * 1.3 if random.uniform(0,1) <= EV_proportion else output )\n",
    "        \n",
    "\n",
    "def generate_axle_number(vehicle_class: int) -> int:\n",
    "    return  generate_variable('Class', vehicle_class, 'No of Axle')\n",
    "\n",
    "def generate_axle_spacing(vehicle_class: int, axle_number: int) -> list[float]:\n",
    "    # finds the axle spacing based on the vehicle_class + axle_number\n",
    "    # find the subset of data that matches with the right vehicle class, then match with the right axle number\n",
    "    # find the cumulative probabiility distribution of each/all axle spacing\n",
    "    output = np.array([])\n",
    "    for spacing_index in range(2,axle_number+1):\n",
    "        axle_spacing_column_name =  'Axle Spacing '+ str(spacing_index)\n",
    "        output = np.append(output, double_filter_and_generate_variable('Class', vehicle_class,'No of Axle',axle_number,axle_spacing_column_name))\n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_axle_weight(vehicle_class: int, axle_number: int, GVW: float)-> list[float]:\n",
    "    output = np.array([])\n",
    "    for spacing_index in range(1,axle_number+1):\n",
    "        axle_weight_column_name =  'Axle Weight '+ str(spacing_index)\n",
    "        output = np.append(output,double_filter_and_generate_variable('Class', vehicle_class,'No of Axle',axle_number,axle_weight_column_name))\n",
    "    \n",
    "    # * normalise and distribute GVW to axle weights. \n",
    "    output = normalise_axle_weights(output)\n",
    "    output = distribute_total_weight(output, GVW)\n",
    "    return output\n",
    "\n",
    "def generate_speed(lane_num: int)-> float:\n",
    "    return generate_variable('Lane', lane_num, 'Speed')\n",
    "\n",
    "def generate_gap_time(vehicle_class: int)-> float:\n",
    "    output = generate_variable('Class', vehicle_class, 'Gap Time')\n",
    "    if type(output) == pd.Series : \n",
    "        output = float(output.iloc[0])\n",
    "    return output\n",
    "\n",
    "def determine_hourly_flow_rate(hour: int)-> float:\n",
    "    # obtain target flow rate based on the hourly flow rate\n",
    "    np_avg_veh_flow = np.array([1746.        , 1155.        ,  760.        ,    0.        ,\n",
    "        0.        ,    0.        ,    0.        ,    0.        ,\n",
    "    4709.        , 5161.        , 4768.        , 3046.        ,\n",
    "    3073.5       , 3482.        , 3177.        , 2696.        ,\n",
    "    2340.        , 2299.5       , 2262.        , 1763.5       ,\n",
    "    1146.        , 3839.66666667, 1582.        ,  658.        ],dtype='i')\n",
    "    return np_avg_veh_flow[hour]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For load_assessment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cars_on_bridge_at_instance(np_generated_traffic_for_the_day: np.float64| np.int8, timer: int, bridge_length: int, index_of_first_veh_on_bridge_last_second: int, index_of_last_veh_on_bridge_last_second: int):\n",
    "    \n",
    "    # print(f'AT THE START {np_generated_traffic_for_the_day[-1][:10]=}')\n",
    "    # * Find the last car on the bridge\n",
    "    index_of_last_veh_on_bridge = index_of_last_veh_on_bridge_last_second + 1\n",
    "    while True:\n",
    "        \n",
    "        if index_of_last_veh_on_bridge >= len(np_generated_traffic_for_the_day[0])-1:\n",
    "            break\n",
    "\n",
    "\n",
    "        if np_generated_traffic_for_the_day[5][index_of_last_veh_on_bridge] > timer:\n",
    "            index_of_last_veh_on_bridge -= 1\n",
    "            break\n",
    "        else: \n",
    "            index_of_last_veh_on_bridge += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "    index_of_first_veh_on_bridge = index_of_last_veh_on_bridge + 1\n",
    "    for car_index in range(index_of_first_veh_on_bridge_last_second,index_of_last_veh_on_bridge+1):\n",
    "        distance_from_start = (timer - np_generated_traffic_for_the_day[5][car_index]) * (np_generated_traffic_for_the_day[4][car_index]/ 3.6)\n",
    "\n",
    "\n",
    "\n",
    "        if distance_from_start <= bridge_length:\n",
    "            index_of_first_veh_on_bridge = car_index \n",
    "            break\n",
    "    else:\n",
    "        index_of_first_veh_on_bridge = index_of_last_veh_on_bridge+1\n",
    "\n",
    "    if index_of_first_veh_on_bridge > index_of_last_veh_on_bridge: \n",
    "        return np.array([]), index_of_first_veh_on_bridge, index_of_last_veh_on_bridge\n",
    "    else:\n",
    "        \n",
    "        np_cars_on_bridge = np_generated_traffic_for_the_day.T[index_of_first_veh_on_bridge:index_of_last_veh_on_bridge+1].T\n",
    "\n",
    "        return np_cars_on_bridge ,index_of_first_veh_on_bridge, index_of_last_veh_on_bridge\n",
    "\n",
    "def setup_list_for_next_HDV_time(np_generated_daily_traffic: np.float64| np.int8, np_generated_traffic_for_the_day: np.float64| np.int8):\n",
    "    next_HDV_time_list = np.array([])\n",
    "    for index in range(len(np_generated_daily_traffic)):\n",
    "        if (np_generated_daily_traffic[index][1] == float(1)): \n",
    "            next_HDV_time_list = np.append(next_HDV_time_list, np.array(index))\n",
    "    next_HDV_time_list = np.take(np_generated_traffic_for_the_day[5], next_HDV_time_list.astype(int))\n",
    "    return next_HDV_time_list.astype(int)\n",
    "\n",
    "\n",
    "def advance_timer_to_next_HDV(np_generated_traffic_for_the_day: np.float64| np.int8, vehicle_indexing_from_last_call: dict[int], total_lane: int, timer: int)-> int:\n",
    "    \n",
    "    next_HDV_cumu_gap_time = 1000000\n",
    "    for index in range(len(np_generated_traffic_for_the_day[0])):\n",
    "\n",
    "        if (np_generated_traffic_for_the_day[1][index] == float(1)) & (np_generated_traffic_for_the_day[5][index] > timer ) & (  np_generated_traffic_for_the_day[5][index] < next_HDV_cumu_gap_time): \n",
    "            next_HDV_cumu_gap_time = np_generated_traffic_for_the_day[5][index]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    return next_HDV_cumu_gap_time\n",
    "\n",
    "\n",
    "def convert_series_type(*items) -> (tuple | float):\n",
    "    if len(items) == 1:\n",
    "        if type(items) == pd.Series:\n",
    "            items = float(items.iloc[0])\n",
    "        return items\n",
    "    for index, item in enumerate(items):\n",
    "        if type(item) == pd.Series:\n",
    "            items[index] = item.iloc[0]\n",
    "    return items\n",
    "\n",
    "def calculate_BM(car_distance_from_start: float ,axle_weight: float , total_axle_spacing: float, bridge_length: int): \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    reaction_force_at_support = axle_weight * (bridge_length - car_distance_from_start) / (bridge_length)\n",
    "    \n",
    "    \n",
    "    moment_arm = car_distance_from_start\n",
    "    \n",
    "    \n",
    "    BM = reaction_force_at_support * car_distance_from_start\n",
    "\n",
    "    BM =  axle_weight * (bridge_length - car_distance_from_start) / (bridge_length) / car_distance_from_start\n",
    "    \n",
    "    return BM\n",
    "\n",
    "\n",
    "def calculate_mid_span_BM(np_cars_on_bridge: np.float64|np.int8, bridge_length: int, top_3_BM_recorded: list[float], timer: int, top_3_BM_one_lane_recorded: np.int16, number_of_measured_lanes: str): \n",
    "\n",
    "    \n",
    "    max_possible_BM = np.sum(np_cars_on_bridge[3]) * bridge_length / 4\n",
    "\n",
    "\n",
    "    \n",
    "    if (number_of_measured_lanes == 'one lane') & ((max_possible_BM) <= min(top_3_BM_one_lane_recorded)): \n",
    "        return 0 , np.array([])\n",
    "    elif (number_of_measured_lanes == 'all lane') & ((max_possible_BM) <= min(top_3_BM_recorded)):\n",
    "        return 0 , np.array([])\n",
    "    total_BM = 0\n",
    "    transposed_np_cars_on_bridge = np_cars_on_bridge.T\n",
    "    output = np.array([])\n",
    "\n",
    "    for element in transposed_np_cars_on_bridge:\n",
    "\n",
    "        car = element\n",
    "\n",
    "        if car[1] == float(2) or car[1] == float(3):\n",
    "            continue\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        car_distance_from_start = int((timer - car[5]) * (car[4] / 3.6))\n",
    "\n",
    "\n",
    "        if ((car_distance_from_start > 0) & (car_distance_from_start < 20)):\n",
    "            if (number_of_measured_lanes == 'all lane'):\n",
    "                axle_number = generate_axle_number(car[2])\n",
    "                if len(output) == 0: \n",
    "                    output = np.append(car,axle_number)\n",
    "                else:\n",
    "                    output = np.vstack((output, np.append(car,axle_number)))\n",
    "\n",
    "\n",
    "            \n",
    "            total_BM += car[3] * car_distance_from_start / 2\n",
    "    if (number_of_measured_lanes == 'all lane'):\n",
    "        output = output.T\n",
    "    return total_BM, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a_vehicle(np_generated_traffic: np.float64|np.int8, lane_num: int, timer: float, hour: int, cumu_gap_time: float, EV_proportion: float):\n",
    "    \n",
    "    vehicle_type, vehicle_class = generate_vehicle_class()\n",
    "    speed = generate_speed(lane_num)\n",
    "    gap_time = generate_gap_time(vehicle_class)\n",
    "\n",
    "    if vehicle_type == 1:\n",
    "        GVW = generate_GVW(vehicle_class, EV_proportion)\n",
    "    else: \n",
    "        GVW = 0\n",
    "\n",
    "\n",
    "\n",
    "    if len(np_generated_traffic) == 0:\n",
    "        cumu_gap_time = 0\n",
    "    else: \n",
    "        cumu_gap_time += gap_time\n",
    "    timer = cumu_gap_time \n",
    "\n",
    "\n",
    "\n",
    "    np_new_vehicle = np.array([lane_num,vehicle_type,vehicle_class,GVW,speed,cumu_gap_time],dtype=float)\n",
    "\n",
    "    if len(np_generated_traffic) == 0:\n",
    "        np_generated_traffic = np_new_vehicle\n",
    "    else: \n",
    "        np_generated_traffic = np.vstack((np_generated_traffic, np_new_vehicle))\n",
    "        \n",
    "    \n",
    "\n",
    "    return np_generated_traffic, timer, cumu_gap_time\n",
    "\n",
    "\n",
    "def generate_hourly_vehicle_stream(np_generated_daily_traffic: np.float64|np.int8, hour: int, lane_num: int, timer: float, cumu_gap_time: float, EV_proportion: float, traffic_growth: float, vehicles_per_hour: int):\n",
    "    np_generated_hourly_traffic = np.array([])\n",
    "    cumu_gap_time = 0\n",
    "\n",
    "\n",
    "    for _ in range(int(vehicles_per_hour * traffic_growth)):\n",
    "        np_generated_hourly_traffic, timer , cumu_gap_time = generate_a_vehicle(np_generated_hourly_traffic, lane_num, timer, hour, cumu_gap_time, EV_proportion)\n",
    "\n",
    "\n",
    "    total_gap_time = float(np_generated_hourly_traffic[-1][5])\n",
    "    for index in range(len(np_generated_hourly_traffic)):\n",
    "        np_generated_hourly_traffic[index][5] = np_generated_hourly_traffic[index][5] * 3600 / total_gap_time + hour * 3600\n",
    "    \n",
    "\n",
    "\n",
    "    if len(np_generated_daily_traffic) == 0:\n",
    "        np_generated_daily_traffic = np_generated_hourly_traffic\n",
    "    else:\n",
    "        np_generated_daily_traffic = np.concatenate((np_generated_daily_traffic, np_generated_hourly_traffic),axis=0)\n",
    "    return  np_generated_daily_traffic\n",
    "\n",
    "\n",
    "    np_generated_daily_traffic_all_lane = np.array([])\n",
    "\n",
    "    for lane_num in range(1,total_lane+1):\n",
    "        timer = 0.0\n",
    "        cumu_gap_time = 0\n",
    "        np_avg_veh_flow = np.array([1746.        , 1155.        ,  760.        ,    0.        ,\n",
    "        0.        ,    0.        ,    0.        ,    0.        ,\n",
    "        4709.        , 5161.        , 4768.        , 3046.        ,\n",
    "        3073.5       , 3482.        , 3177.        , 2696.        ,\n",
    "        2340.        , 2299.5       , 2262.        , 1763.5       ,\n",
    "        1146.        , 3839.66666667, 1582.        ,  658.        ],dtype='i')\n",
    "\n",
    "        for hour in range(hours_in_a_day):\n",
    "\n",
    "            if np_avg_veh_flow[hour] != 0:\n",
    "                np_generated_daily_traffic_all_lane = generate_hourly_vehicle_stream(np_generated_daily_traffic_all_lane, hour, lane_num, timer, cumu_gap_time, EV_proportion, traffic_growth, np_avg_veh_flow[hour])\n",
    "        \n",
    "        \n",
    "            \n",
    "    return np_generated_daily_traffic_all_lane\n",
    "\n",
    "\n",
    "def load_assessment(np_generated_daily_traffic: np.float64|np.int8, top_3_BM_recorded: list[float], top_3_BM_dict_cars_on_bridge: dict, hours_in_a_day: int, total_lane: int, top_3_BM_one_lane_recorded: np.int16 , new_BM_recorded: np.float64, new_BM_dict_cars_on_bridge: dict, new_BM_one_lane_recorded: np.float64, multiprocessing: bool)-> tuple[float, pd.DataFrame]: \n",
    "    bridge_length = 50\n",
    "    seconds_in_a_day = 60 * 60 * hours_in_a_day\n",
    "    timer = 0 \n",
    "    vehicle_indexing_from_last_call = {}\n",
    "    max_cumu_gap_time = 9000000\n",
    "    previous_next_HDV_time_list_index = 0\n",
    "    np_generated_traffic_for_the_day = np_generated_daily_traffic.T\n",
    "\n",
    "    next_HDV_time_list = setup_list_for_next_HDV_time(np_generated_daily_traffic, np_generated_traffic_for_the_day)\n",
    "\n",
    "    for lane in range(1,total_lane+1):\n",
    "        vehicle_indexing_from_last_call['first ' + str(lane)] = 0\n",
    "        vehicle_indexing_from_last_call['last ' + str(lane)] = 0\n",
    "    max_cumu_gap_time = np_generated_traffic_for_the_day[5][-1]\n",
    "\n",
    "\n",
    "    np_generated_traffic_in_each_lane = {}\n",
    "    for lane in range(1,total_lane+1):\n",
    "        np_generated_traffic_in_each_lane[lane] = np_generated_daily_traffic[np_generated_traffic_for_the_day[0] == lane].T\n",
    "    \n",
    "    while timer <= seconds_in_a_day:\n",
    "\n",
    "        if timer >= max_cumu_gap_time:\n",
    "            break\n",
    "\n",
    "        np_cars_on_bridge = np.array([])\n",
    "        total_load_effect = 0\n",
    "\n",
    "        for lane in range(1,total_lane+1):\n",
    "            \n",
    "            \n",
    "            np_cars_on_bridge_one_lane , vehicle_indexing_from_last_call['first ' + str(lane)], vehicle_indexing_from_last_call['last ' + str(lane)] = count_cars_on_bridge_at_instance(np_generated_traffic_in_each_lane[lane], timer, bridge_length, vehicle_indexing_from_last_call['first ' + str(lane)], vehicle_indexing_from_last_call['last ' + str(lane)])\n",
    "\n",
    "\n",
    "            if len(np_cars_on_bridge) == 0:\n",
    "                np_cars_on_bridge = np_cars_on_bridge_one_lane\n",
    "\n",
    "            elif (len(np_cars_on_bridge) != 0) & (len(np_cars_on_bridge_one_lane) != 0):\n",
    "                np_cars_on_bridge = np.concatenate((np_cars_on_bridge, np_cars_on_bridge_one_lane),1)\n",
    "\n",
    "            if len(np_cars_on_bridge_one_lane) != 0:\n",
    "                load_effect, np_cars_on_bridge_one_lane = calculate_mid_span_BM(np_cars_on_bridge_one_lane, bridge_length, top_3_BM_recorded, timer, top_3_BM_one_lane_recorded, 'one lane')\n",
    "\n",
    "                if load_effect > min(top_3_BM_one_lane_recorded):\n",
    "                    if multiprocessing:\n",
    "                        np.hstack((new_BM_one_lane_recorded,np.array(load_effect)))\n",
    "                    else:\n",
    "                        min_index = np.where(top_3_BM_one_lane_recorded == min(top_3_BM_one_lane_recorded))[0][0]\n",
    "                        top_3_BM_one_lane_recorded[min_index] = load_effect\n",
    "                \n",
    "            if len(np_cars_on_bridge) != 0:\n",
    "                if lane == total_lane:\n",
    "                    total_load_effect, np_cars_on_bridge = calculate_mid_span_BM(np_cars_on_bridge, bridge_length, top_3_BM_recorded, timer, top_3_BM_one_lane_recorded , 'all lane')\n",
    "\n",
    "                    if total_load_effect > min(top_3_BM_recorded):\n",
    "                        if multiprocessing:\n",
    "                            new_BM_recorded = np.hstack((new_BM_recorded,np.array(total_load_effect)))\n",
    "                            new_BM_dict_cars_on_bridge[len(new_BM_recorded)-1] = np_cars_on_bridge\n",
    "\n",
    "                        else:\n",
    "                            min_index = np.where(top_3_BM_recorded == min(top_3_BM_recorded))[0][0]\n",
    "                            top_3_BM_recorded[min_index] = total_load_effect\n",
    "                            top_3_BM_dict_cars_on_bridge[min_index] = np_cars_on_bridge\n",
    "        timer += 1\n",
    "        if len(np_cars_on_bridge) == 0: \n",
    "            pos_increment = 1\n",
    "            while previous_next_HDV_time_list_index + pos_increment < len(next_HDV_time_list)-1:\n",
    "                next_HDV_time = next_HDV_time_list[previous_next_HDV_time_list_index+pos_increment]\n",
    "                if next_HDV_time > timer:\n",
    "                    timer = next_HDV_time\n",
    "                    previous_next_HDV_time_list_index += pos_increment\n",
    "                    break\n",
    "                pos_increment += 1\n",
    "            else:\n",
    "                if multiprocessing:\n",
    "                    return new_BM_recorded, new_BM_dict_cars_on_bridge, new_BM_one_lane_recorded\n",
    "                else:\n",
    "                    return top_3_BM_recorded, top_3_BM_dict_cars_on_bridge, top_3_BM_one_lane_recorded\n",
    "\n",
    "    if multiprocessing:\n",
    "        return new_BM_recorded, new_BM_dict_cars_on_bridge, new_BM_one_lane_recorded\n",
    "    else:\n",
    "        return top_3_BM_recorded, top_3_BM_dict_cars_on_bridge, top_3_BM_one_lane_recorded\n",
    "\n",
    "\n",
    "def save_to_SQL():\n",
    "    return\n",
    "\n",
    "def load_max_BM_from_excel() -> tuple[pd.DataFrame]:\n",
    "    xls = pd.ExcelFile(\"Final_Year_Project/max_BM_record.xlsx\")\n",
    "    df1 = pd.read_excel(xls, 'Max BM Value', header=1)\n",
    "    \n",
    "    top_3_BM_recorded = float(df1['top_3_BM_recorded'])\n",
    "    day = int(df1['day'])\n",
    "\n",
    "    top_3_BM_df_cars_on_bridge = pd.read_excel(xls, 'Max BM Traffic Configuration', header=1)\n",
    "    return day, top_3_BM_recorded, top_3_BM_df_cars_on_bridge\n",
    "\n",
    "\n",
    "def string_to_list(string: str)-> list[float]| int:\n",
    "\n",
    "    if string == '0':\n",
    "        return 0\n",
    "    elif type(string) != str:\n",
    "        return string\n",
    "    else: \n",
    "        tmp = string.lstrip('[\" ')\n",
    "        tmp = tmp.rstrip(']\" ')\n",
    "        if ' ' in tmp:\n",
    "            tmp.split(' ')\n",
    "            while True: \n",
    "                tmp1 = tmp.replace('  ',' ')\n",
    "                if tmp1==tmp: \n",
    "                    break \n",
    "                else:\n",
    "                    tmp = tmp1\n",
    "            return [float(x) for x in tmp.split(' ')]\n",
    "        else: \n",
    "            return [float(tmp)]\n",
    "\n",
    "\n",
    "def load_sim_info_from_csv(filename: str):\n",
    "    output = pd.read_csv(filename, header=None)\n",
    "    output = output.to_numpy()\n",
    "    return output\n",
    "\n",
    "def load_days_from_csv(filename: str):\n",
    "    output = pd.read_csv(filename, header=None).iloc[0,0]\n",
    "    return output\n",
    "\n",
    "def load_output_from_csv(filename: str):\n",
    "    output = pd.read_csv(filename, header=None)\n",
    "\n",
    "\n",
    "    for column in range(len(output.columns)):\n",
    "        if column == 1:\n",
    "            continue\n",
    "        else: \n",
    "            output.iloc[:,column] = output.iloc[:,column].astype(float)\n",
    "    \n",
    "    return output.to_numpy()\n",
    "\n",
    "\n",
    "def save_to_csv(filename:str , item: np.float64 | np.int8 | list[float])-> None:\n",
    "    if type(item) == int:\n",
    "        with open(filename, 'w') as csv_file:\n",
    "            csv.writer(csv_file).writerow([item])\n",
    "    else:\n",
    "        pd.DataFrame(item).to_csv(filename,header=False, index=False) \n",
    "    return\n",
    "\n",
    "def load_top_BM_from_csv(filepath: str):\n",
    "    top_3_BM_recorded = np.genfromtxt(filepath, delimiter=',')\n",
    "    return top_3_BM_recorded\n",
    "\n",
    "def load_top_BM_np_from_csv(filepath1: str, filepath2: str, filepath3: str):\n",
    "    top_3_BM_dict_cars_on_bridge = {}\n",
    "    \n",
    "    for key in range(3):\n",
    "        filepath = [filepath1,filepath2, filepath3][key]\n",
    "\n",
    "        \n",
    "        top_3_BM_dict_cars_on_bridge[key] = load_output_from_csv(filepath)\n",
    "\n",
    "    return top_3_BM_dict_cars_on_bridge\n",
    "\n",
    "def check_and_update_sim_info(day:int, simulation_information: np.float64| np.int8, top_3_BM_recorded: np.float64):\n",
    "    year = day / 365\n",
    "    if year in simulation_information[0]:\n",
    "        simulation_information[1][np.where(simulation_information[0] == year)] = np.max(top_3_BM_recorded)\n",
    "    return simulation_information\n",
    "\n",
    "def Monte_Carlo_Simulation_One_Year():\n",
    "    hours_in_a_day = 1\n",
    "    total_lane = 3\n",
    "    EV_proportion = 1\n",
    "    traffic_growth = 3.75\n",
    "    debugger_mode = False\n",
    "    multiprocessing = False\n",
    "\n",
    "    top_3_BM_recorded_filepath = 'Simulation_Results/top_3_BM.csv'\n",
    "    top_3_BM_one_lane_recorded_filepath = 'Simulation_Results/top_3_BM_one_lane.csv'\n",
    "    day_filepath = 'Simulation_Results/day.csv'\n",
    "    simulation_information_filepath = 'Simulation_Results/simulation_information.csv'\n",
    "    top_3_BM_dict_cars_on_bridge0_filepath = 'Simulation_Results/max_BM_record1.csv'\n",
    "    top_3_BM_dict_cars_on_bridge1_filepath = 'Simulation_Results/max_BM_record2.csv'\n",
    "    top_3_BM_dict_cars_on_bridge2_filepath = 'Simulation_Results/max_BM_record3.csv'\n",
    "\n",
    "    new_BM_recorded = np.array([0,0,0])\n",
    "    new_BM_dict_cars_on_bridge = {}\n",
    "    new_BM_one_lane_recorded = np.array([0,0,0])\n",
    "\n",
    "\n",
    "\n",
    "    top_3_BM_recorded = np.array([0,0,0])\n",
    "    top_3_BM_dict_cars_on_bridge = {}\n",
    "\n",
    "    top_3_BM_one_lane_recorded = np.array([0,0,0])\n",
    "    \n",
    "    if multiprocessing:\n",
    "        total_number_of_days = 365\n",
    "    else:\n",
    "        total_number_of_days = 365 * 2400\n",
    "\n",
    "    simulation_information = load_sim_info_from_csv(simulation_information_filepath)\n",
    "    day = int(load_days_from_csv(day_filepath))\n",
    "\n",
    "\n",
    "    while day <= total_number_of_days:\n",
    "         \n",
    "\n",
    "        if debugger_mode:\n",
    "            np_generated_daily_traffic = load_output_from_csv('Simulation_Results/generated_daily_vehicle_stream.csv')\n",
    "        else:\n",
    "            np_generated_daily_traffic = generate_daily_vehicle_stream(hours_in_a_day, total_lane, EV_proportion, traffic_growth)\n",
    "            top_3_BM_recorded, top_3_BM_dict_cars_on_bridge, top_3_BM_one_lane_recorded =  load_top_BM_from_csv(top_3_BM_recorded_filepath), load_top_BM_np_from_csv(top_3_BM_dict_cars_on_bridge0_filepath,top_3_BM_dict_cars_on_bridge1_filepath,top_3_BM_dict_cars_on_bridge2_filepath), load_top_BM_from_csv(top_3_BM_one_lane_recorded_filepath)\n",
    "        new_top_3_BM_recorded, new_top_3_BM_dict_cars_on_bridge, new_top_3_BM_one_lane_recorded = load_assessment(np_generated_daily_traffic, top_3_BM_recorded, top_3_BM_dict_cars_on_bridge, hours_in_a_day, total_lane, top_3_BM_one_lane_recorded, new_BM_recorded, new_BM_dict_cars_on_bridge, new_BM_one_lane_recorded, multiprocessing)\n",
    "        day += 1\n",
    "    return top_3_BM_recorded, top_3_BM_dict_cars_on_bridge, top_3_BM_one_lane_recorded\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        Monte_Carlo_Simulation_One_Year()\n",
    "    return\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
